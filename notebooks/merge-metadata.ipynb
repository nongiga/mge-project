{
 "cells": [
  {
   "source": [
    "## To merge:\n",
    " - Mathew's matlab data\n",
    " - my cluster identification data\n",
    " - mgefinder\n",
    " - breseq (one day, hopefully)\n"
   ],
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add same strain data to awkward array so that each isolate has \n",
    "#   1. whether it is a part of a same-strain subset (true/false for filtering)\n",
    "#   2. the # of SNPs between it and its colleagues\n",
    "import sys\n",
    "sys.path.append('PycharmProjects/mge-project/scripts/')\n",
    "from presnakemake_processing import process_same_strain_file\n",
    "same_strain_list=process_same_strain_file(\"~/PycharmProjects/mge-project/workflow/config/All_same_strain_pairs.xlsx\")\n"
   ]
  },
  {
   "source": [
    "## Task #1: import all data into person\n",
    "### Use dask when possible"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "isolates_list=(pd.read_excel(\"~/PycharmProjects/mge-project/workflow/config/isolates_list_Maccabi_E.coli_UTI_SeqPlates1to25.xlsx\",\n",
    "     engine=\"openpyxl\")\n",
    "    .dropna(axis=1,how=\"all\") \\\n",
    "    .dropna(axis=0,how=\"all\") \\\n",
    "    .convert_dtypes(convert_floating=False)\n",
    "    .SampleDate.apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#created nested struct and awkward array from excel\n",
    "df=isolates_list\n",
    "ilj = (df.groupby(['NewRandomID','RandomID','CaseNum'])\n",
    "             .apply(lambda x: x[['IsoNum', 'RowNum','SampleDate','SeqSubDirName','LowQualityThrs', 'Freezer_pos', 'Used', 'SiteString']]\n",
    "             .to_dict(\"records\"))\n",
    "             .reset_index()\n",
    "             .rename(columns={0:'Isolates'})\n",
    "             .to_json(orient='records'))\n",
    "#print(json.dumps(json.loads(ilj), indent=2, sort_keys=True))\n",
    "\n",
    "ila=ak.from_json(ilj)\n",
    "\n",
    "#add raw seqname to struct\n",
    "counts=ak.num(ila.Isolates)\n",
    "Seqname=[str(s).replace('Maccabi_Ecoli_SeqPlate','').replace('Sample_','') for s in ak.flatten(ila.Isolates.SeqSubDirName)]\n",
    "Seqname=ak.unflatten(Seqname, counts)\n",
    "ila['Isolates']=ak.with_field(ila.Isolates, Seqname, where=\"Seqname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# process same-strain into json and then awkwardarray\n",
    "#sd = (same_strain_list.groupby(['RandomID']).aggregate(list)).to_dict()\n",
    "from presnakemake_processing import process_same_strain_file\n",
    "same_strain_list=process_same_strain_file(\"~/PycharmProjects/mge-project/workflow/config/All_same_strain_pairs.xlsx\")\n",
    "ssj = (same_strain_list.groupby('RandomID')['Seqplates']\n",
    "             .apply(list)\n",
    "             .reset_index()\n",
    "             .rename(columns={0:'Isolates'})\n",
    "             .to_json(orient='records'))\n",
    "\n",
    "#print(json.dumps(json.loads(ssj), indent=2, sort_keys=True))\n",
    "ssa=ak.from_json(ssj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge two arrays in outer join\n",
    "dictionary, index = np.unique(np.asarray(ssa.RandomID), return_index=True)\n",
    "closest = np.searchsorted(dictionary, np.asarray(ila.RandomID), side=\"left\")\n",
    "is_within_range = ak.Array(closest).mask[closest < len(dictionary)]\n",
    "is_good_match = ak.Array(dictionary)[is_within_range] == ila.RandomID\n",
    "print(ila.RandomID)\n",
    "reordering = ak.Array(closest).mask[is_good_match]\n",
    "ila[\"Seqplates\"] = ssa.Seqplates[index][reordering]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add same-strain using cartesian product\n",
    "cart=ak.cartesian([ila.Isolates.Seqname, ila.Seqplates], nested=True)\n",
    "is_ss=ak.any(cart.slot0==cart.slot1, axis=-1)\n",
    "is_ss=ak.fill_none(is_ss, False)\n",
    "ila['Isolates']=ak.with_field(ila.Isolates, is_ss, where=\"IsSameStrain\")"
   ]
  },
  {
   "source": [
    "## Task #2: import pangenome coverage data\n",
    "The absolute necessaries:\n",
    " - gene names (from roary)\n",
    " - gene functions, scaffolds (from prokka)\n",
    " - gene coverages (from coverage)\n",
    " - BRESEQ\n",
    " \n",
    "All else can wait!\n",
    "### Work plan\n",
    " Load into pangenomes structs and then merge them with dataset at very end"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# get all gene_presence_absence files (older version, works)\n",
    "\n",
    "\n",
    "# import pyarrow as pa\n",
    "# from pyarrow import csv\n",
    "# import pyarrow.parquet as pq\n",
    "\n",
    "# datadir=os.getcwd()+\"/PycharmProjects/mge-project/data/\"\n",
    "\n",
    "# dirnames=np.char.add(np.asarray(datadir+\"/pangenome/\", dtype=str), np.asarray(ila.NewRandomID,dtype=str))\n",
    "# filenames=np.char.add(dirnames,np.asarray('/gene_presence_absence.csv', dtype=str))\n",
    "\n",
    "# isfile=[os.path.isfile(fn) for fn in filenames]\n",
    "\n",
    "# def ak_string_to_int(akstr):\n",
    "#     nparr=ak.to_numpy(akstr,allow_missing=True)\n",
    "#     nparr=np.fromstring(nparr, dtype=int)\n",
    "#     akint=ak.Array(nparr)\n",
    "#     return akint\n",
    "\n",
    "\n",
    "# #get pandas table\n",
    "# def get_pangenome_data(filename,opt):\n",
    "#     roary_pa=csv.read_csv(filename, convert_options=opt)\n",
    "#     roary_pa=roary_pa.rename_columns([n.replace(' ', '_').replace('.','') for n in roary_pa.column_names])\n",
    "#     roary_pa=roary_pa.drop([col for col in roary_pa.column_names if 'Sample' in col])\n",
    "#     print(filename)\n",
    "#     roary_ak=ak.from_arrow(roary_pa)\n",
    "#     # roary_ak.Accessory_Fragment=ak_string_to_int(roary_ak.Accessory_Fragment)\n",
    "#     # roary_ak.Accessory_Order_with_Fragment=ak_string_to_int(roary_ak.Accessory_Order_with_Fragment)\n",
    "\n",
    "#     return roary_ak, ak.num(roary_ak.Gene, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ilp=ila[:4]\n",
    "# isfile=isfile[:4]\n",
    "# filenames=filenames[:4]\n",
    "\n",
    "# opt=csv.ConvertOptions(column_types=[('Accessory Fragment', pa.string()),( 'Accessory Order with Fragment', pa.string() )],\n",
    "#         strings_can_be_null=True)\n",
    "\n",
    "\n",
    "\n",
    "# rda=ak.to_arrow(ilp)\n",
    "\n",
    "# roary_data=[ (get_pangenome_data(fn, opt))  for fn in filenames[isfile] ]\n",
    "\n",
    "# r_count=np.array([c[1] for c in roary_data])\n",
    "# count=np.zeros((len(ilp),),dtype=int)\n",
    "# count[isfile]=r_count\n",
    "\n",
    "# roary_data=[c[0] for c in roary_data]\n",
    "\n",
    "\n",
    "# rd=ak.concatenate(roary_data,merge=False, mergebool=False)\n",
    "# rd=ak.unflatten(rd,count)\n",
    "\n",
    "# ilp=ak.with_field(ilp, rd, where='Pangenome')\n",
    "# print(ak.type(ilp))\n",
    "\n",
    "# ak.to_parquet(ilp, datadir+\"/datastruct/up_to_pangenome.parquet\")\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# get all gene_presence_absence files (older version, works)\n",
    "\n",
    "\n",
    "import pyarrow as pa\n",
    "from pyarrow import csv\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "datadir=os.getcwd()+\"/PycharmProjects/mge-project/data/\"\n",
    "\n",
    "dirnames=np.char.add(np.asarray(datadir+\"/pangenome/\", dtype=str), np.asarray(ila.NewRandomID,dtype=str))\n",
    "filenames=np.char.add(dirnames,np.asarray('/gene_presence_absence.csv', dtype=str))\n",
    "\n",
    "isfile=[os.path.isfile(fn) for fn in filenames]\n",
    "\n",
    "def ak_string_to_int(akstr):\n",
    "    nparr=ak.to_numpy(akstr,allow_missing=True)\n",
    "    nparr=np.fromstring(nparr, dtype=int)\n",
    "    akint=ak.Array(nparr)\n",
    "    return akint\n",
    "\n",
    "ilp=ila\n",
    "\n",
    "roary_pd= [pd.read_csv(fn, error_bad_lines=False) for fn in filenames[isfile]]\n",
    "\n",
    "count=np.zeros((len(ilp),),dtype=int)\n",
    "count_r= [len(rpd.index) for rpd in roary_pd]\n",
    "count[isfile]=count_r\n",
    "\n",
    "merged_rpd=pd.concat(roary_pd, ignore_index=True)\n",
    "par=pa.Table.from_pandas(merged_rpd)\n",
    "rd=ak.from_arrow(par)\n",
    "\n",
    "rd=ak.unflatten(rd,count)\n",
    "\n",
    "ilp=ak.with_field(ilp, rd, where='Pangenome')\n",
    "\n",
    "print(ak.type(ilp))\n",
    "\n",
    "ak.to_parquet(ilp, datadir+\"/datastruct/up_to_pangenome.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}